/**
 * ç«å±±å¼•æ“WebSocketå•å‘æµå¼TTSå®ç°
 *
 * æ–‡æ¡£: https://www.volcengine.com/docs/6561/1598757
 *
 * ç‰¹ç‚¹ï¼š
 * - ä½¿ç”¨WebSocketåè®®
 * - å•å‘æµå¼ï¼ˆæœåŠ¡ç«¯ä¸»åŠ¨æ¨é€éŸ³é¢‘ï¼‰
 * - äºŒè¿›åˆ¶åè®®ä¼ è¾“
 * - ä½å»¶è¿Ÿï¼Œé€‚åˆå®æ—¶åœºæ™¯
 */

import WebSocket from 'ws'
import { v4 as uuidv4 } from 'uuid'
import { loadVolcEngineConfig } from './auth'
import type { TTSRequest } from './types'
import {
  MsgType,
  EventType,
  ReceiveMessage,
  FullClientRequest,
} from './protocols'

/**
 * éŸ³è‰²IDåˆ°ResourceIDçš„æ˜ å°„
 */
function VoiceToResourceId(voice: string): string {
  if (voice.startsWith('S_')) {
    return 'volc.megatts.default'  // ICLéŸ³è‰²
  }
  return 'volc.service_type.10029'  // å¤§æ¨¡å‹éŸ³è‰²
}

/**
 * WebSocketå•å‘æµå¼TTSç±»
 */
export class VolcEngineWebSocketTTS {
  private config: ReturnType<typeof loadVolcEngineConfig>
  private endpoint: string
  private timeout: number

  constructor(timeout: number = 60000) {
    this.config = loadVolcEngineConfig()
    this.endpoint = 'wss://openspeech.bytedance.com/api/v3/tts/unidirectional/stream'
    this.timeout = timeout

    // éªŒè¯é…ç½®
    if (!this.config.appId || !this.config.accessKeyId) {
      throw new Error('ç«å±±å¼•æ“é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡')
    }
  }

  /**
   * è¯­éŸ³åˆæˆï¼ˆä¸»å…¥å£ï¼‰
   *
   * @param text è¦åˆæˆçš„æ–‡å­—
   * @param options å¯é€‰é…ç½®
   * @returns éŸ³é¢‘æ•°æ®Buffer
   */
  async synthesize(text: string, options?: Partial<TTSRequest>): Promise<Buffer> {
    // 1. å‚æ•°éªŒè¯
    if (!text || text.trim().length === 0) {
      throw new Error('åˆæˆæ–‡å­—ä¸èƒ½ä¸ºç©º')
    }

    if (text.length > 5000) {
      throw new Error('æ–‡å­—é•¿åº¦ä¸èƒ½è¶…è¿‡5000å­—ç¬¦')
    }

    const voiceType = options?.voiceType || 'zh_female_shuangkuaisisi_moon_bigtts'
    const format = options?.format || 'mp3'
    const speed = options?.speed || 1.0
    const volume = options?.volume || 80

    // 2. å»ºç«‹WebSocketè¿æ¥
    const ws = await this.connect(voiceType)

    try {
      // 3. å‘é€åˆæˆè¯·æ±‚
      await this.sendRequest(ws, text, voiceType, format, speed, volume)

      // 4. æ¥æ”¶æµå¼éŸ³é¢‘
      const audioBuffer = await this.receiveAudio(ws)

      return audioBuffer
    } finally {
      // 5. å…³é—­è¿æ¥
      ws.close()
    }
  }

  /**
   * å»ºç«‹WebSocketè¿æ¥
   */
  private async connect(voiceType: string): Promise<WebSocket> {
    const headers = {
      'X-Api-App-Key': this.config.appId,
      'X-Api-Access-Key': this.config.accessKeyId,
      'X-Api-Resource-Id': VoiceToResourceId(voiceType),
      'X-Api-Connect-Id': uuidv4(),
    }

    console.log('ğŸ”Œ å»ºç«‹WebSocketè¿æ¥...')
    console.log('Headers:', JSON.stringify(headers, null, 2))

    const ws = new WebSocket(this.endpoint, {
      headers,
      skipUTF8Validation: true,
    })

    // ç­‰å¾…è¿æ¥æ‰“å¼€
    await new Promise<void>((resolve, reject) => {
      const timeoutId = setTimeout(() => {
        reject(new Error('WebSocketè¿æ¥è¶…æ—¶'))
      }, 10000)

      ws.on('open', () => {
        clearTimeout(timeoutId)
        console.log('âœ… WebSocketè¿æ¥å·²å»ºç«‹')
        resolve()
      })

      ws.on('error', (error) => {
        clearTimeout(timeoutId)
        reject(error)
      })
    })

    return ws
  }

  /**
   * å‘é€åˆæˆè¯·æ±‚
   */
  private async sendRequest(
    ws: WebSocket,
    text: string,
    voiceType: string,
    format: string,
    speed: number,
    volume: number
  ): Promise<void> {
    const request = {
      user: {
        uid: uuidv4(),
      },
      req_params: {
        speaker: voiceType,
        text: text,
        audio_params: {
          format: format,
          sample_rate: 24000,
          enable_timestamp: true,
          speed: speed,
          volume: volume,
        },
        additions: JSON.stringify({
          disable_markdown_filter: false,
        }),
      },
    }

    console.log('ğŸ“¤ å‘é€TTSè¯·æ±‚:', JSON.stringify(request, null, 2))

    await FullClientRequest(
      ws,
      new TextEncoder().encode(JSON.stringify(request))
    )
  }

  /**
   * æ¥æ”¶æµå¼éŸ³é¢‘
   */
  private async receiveAudio(ws: WebSocket): Promise<Buffer> {
    const totalAudio: Uint8Array[] = []
    const startTime = Date.now()

    console.log('ğŸ“¥ å¼€å§‹æ¥æ”¶éŸ³é¢‘æ•°æ®...')

    while (true) {
      // è¶…æ—¶æ£€æŸ¥
      if (Date.now() - startTime > this.timeout) {
        throw new Error('TTSåˆæˆè¶…æ—¶')
      }

      const msg = await ReceiveMessage(ws)
      console.log(`${msg.toString()}`)

      switch (msg.type) {
        case MsgType.FullServerResponse:
          // æœåŠ¡å™¨å“åº”æ¶ˆæ¯ï¼ˆå¯èƒ½åŒ…å«çŠ¶æ€ä¿¡æ¯ï¼‰
          if (msg.event === EventType.SessionFinished) {
            console.log('âœ… ä¼šè¯ç»“æŸï¼ŒéŸ³é¢‘æ¥æ”¶å®Œæˆ')
            break  // è·³å‡ºwhileå¾ªç¯
          }
          break

        case MsgType.AudioOnlyServer:
          // éŸ³é¢‘æ•°æ®å—
          totalAudio.push(msg.payload)
          console.log(`ğŸµ æ”¶åˆ°éŸ³é¢‘å—: ${msg.payload.length} bytes`)
          break

        default:
          throw new Error(`æœªçŸ¥æ¶ˆæ¯ç±»å‹: ${msg.toString()}`)
      }

      // æ£€æŸ¥æ˜¯å¦ç»“æŸ
      if (
        msg.type === MsgType.FullServerResponse &&
        msg.event === EventType.SessionFinished
      ) {
        break
      }
    }
    if (totalAudio.length === 0) {
      throw new Error('æœªæ”¶åˆ°ä»»ä½•éŸ³é¢‘æ•°æ®')
    }

    // æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘å—
    const totalLength = totalAudio.reduce((sum, chunk) => sum + chunk.length, 0)
    const result = Buffer.alloc(totalLength)
    let offset = 0

    for (const chunk of totalAudio) {
      result.set(chunk, offset)
      offset += chunk.length
    }

    console.log(`âœ… éŸ³é¢‘æ¥æ”¶å®Œæˆï¼Œæ€»å¤§å°: ${result.length} bytes`)
    return result
  }
}

/**
 * ä¾¿æ·å‡½æ•°ï¼šä½¿ç”¨WebSocketåˆæˆè¯­éŸ³
 */
export async function synthesizeSpeech(
  text: string,
  options?: Partial<TTSRequest>
): Promise<Buffer> {
  const tts = new VolcEngineWebSocketTTS()
  return tts.synthesize(text, options)
}
